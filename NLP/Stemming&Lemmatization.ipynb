{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b27d7c0c-d76e-48e4-bc86-0f6926ce8fff",
   "metadata": {},
   "source": [
    "### What is Stemming? \n",
    "\n",
    "* Stemming, in literal terms, is the process of cutting down the branches of a tree to its stem. So\n",
    "effectively, with the use of some basic rules, any token can be cut down to its stem `(base form)`. Stemming is more of\n",
    "a crude rule-based process by which we want to club together different variations of the token.  \n",
    "\n",
    "* `For example:`, the word eat will have variations like `eating`, `eaten`, `eats`, and so on. In some applications, as it\n",
    "does not make sense to differentiate between `eat` and `eaten`, we typically use `stemming` to club both\n",
    "grammatical variances to the root of the word. \n",
    "\n",
    "* While stemming is used most of the time for its\n",
    "simplicity, there are cases of complex language or complex NLP tasks where it's necessary to use\n",
    "lemmatization instead. \n",
    "\n",
    "* Lemmatization is a more robust and methodical way of combining grammatical\n",
    "variations to the root of a word.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f740ac9d-db2d-445f-8755-6d49ee65f474",
   "metadata": {},
   "source": [
    "<center><img src=https://doc-08-2g-docs.googleusercontent.com/docs/securesc/0bijdf7v3f5imfmh3u0vu2rf9sl75noc/gsq8vnvlf3qstjm0880a95c1fbtsjr9m/1653918675000/17830731333114781815/10219751309564329824/1XcK3OzdPd2ywO8Y4G6vfjuIFthPce3FH?e=view&ax=ACxEAsYnwO9hoyM_O9YXoM9tzVJiDAOW8uiQV0pO3Rj2AzXOxk_dTMncFHmbvOt3i2rzkSthm57mgoujH7YOfM9H-Id-NtzxrABJViNSCgWd8UQMaqi8EHXj6UoiV89f25ns7Y6r7m4wD8AMpNP_04K_1yU7aR9-pkh0Pq-r88jX7xo4CR7Vxg11h9YQ8t4mXRcchF6onrdM0bRXKkBI_K0LcDAhoTN6h5CU5ev52PTcsBleVx7JkQzvq8RGYvAXhJdKKGTKhWJ6pPyVSq9lgHXrlZMd31qYWgZwaayBfReKK8CU39kANguLnuHLEsH3Kbwrz0PlMl6bNLJHVhIsuFWW2BLE93WA4-hBFtYf4Q3OwIZXs05jnbAdDzxcVaFjuX8W8BGslSdBl75CkYzVVv5d__c7d-jGE6azi9Bg4wfty1vsFtm3uQKxon2oB7U7HW6cClCS6wNFUvAGtJzNmZsjiVxfuTbD1QQ9tTQ572NLXNPmjobnAXbCsNBE5zCXd7lo6NLbxnywkoGgUq1SdbfgAdEnfioGBoqccbMQyBprS8rHfcgnjgEbEQcG47kEE0kJmjl_sPU3cMwvQ880fLlUsMfyFP29DjGGlZcz2vy6Ebu8uHPSeM64NDWcSA3BhtswgOiby6vSk2yt-R2103DveeB5JzZr87wd6mUx5o_ZnCJsw5Twi5yxsLI-iP5H_6Uo-DvPiNelbmY&authuser=0\" width=\"800\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b7f77b-adeb-450f-b276-3d8178a51352",
   "metadata": {},
   "source": [
    "* where we are interested in stripping the `*suffix*` at the end of the word. When stemming we are interesting in reducing the `*inflected` or `*derived*` word to it's base form. Take a look at the figure above to get some intuition about the process.\n",
    "* where the stems and affixes (called the `*morphemes*`) are extracted and used to reduce inflections to their base form. For instance, the word `*cats*` has two morphemes, `*cat*` and `*s*`, the `*cat*` being the stem and the `*s*` being the **`affix`** representing plurality.\n",
    "* Stemming is most commonly used by search engines for indexing words. Instead of storing all forms of\n",
    "a word, a search engine can store only the stems, greatly reducing the size of index while increasing\n",
    "retrieval accuracy.\n",
    "\n",
    "There are different types of stemmig algorithm are there, let's see one by one! \n",
    "\n",
    "\n",
    "<center><img src=\"https://www.tutorialspoint.com/natural_language_toolkit/images/stemming_algorithms.jpg\" width=\"600\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037a3205-4863-4f6e-9d62-2af794d9cc5d",
   "metadata": {},
   "source": [
    "A basic rule-based stemmer, like removing `â€“s/es` or `-ing` or `-ed` can give you a precision of more than `70`\n",
    "percent, while **`Porter stemmer`** also uses more rules and can achieve very good accuracies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c7629db-c7da-4321-bd43-40a9ae4b35ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shop'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see the porter stemmer in code! \n",
    "from nltk.stem import PorterStemmer # import Porter stemmer\n",
    "\n",
    "pst = PorterStemmer() # create obj of the PorterStemmer\n",
    "\n",
    "pst.stem(\"shopping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93da0248-44a4-40c5-806b-8e1f322ce1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i prefer not to argu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the preceding example! \n",
    "pst.stem('I prefer not to argue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dbc39e-ce39-484d-afa9-52ee3e3c87bc",
   "metadata": {},
   "source": [
    "* However there are many\n",
    "stemming algorithms around, and the `precision `and `performance` of them differ. You may want to have a\n",
    "look at [**here**](http://www.nltk.org/api/nltk.stem.html) for more details. \n",
    "\n",
    "* I have used `Porter Stemmer` most often,\n",
    "and if you are working with English, it's good enough. There is a family of **`Snowball stemmers`** that can\n",
    "be used for Dutch, English, French, German, Italian, Portuguese, Romanian, Russian, and so on. I also\n",
    "came across a light weight stemmer for Hindi on [**here**](http://research.variancia.com/hindi_stemmer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3be469a-c086-406a-9be8-4b267a033a2f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting snowballstemmer\n",
      "  Using cached snowballstemmer-2.2.0-py2.py3-none-any.whl (93 kB)\n",
      "Installing collected packages: snowballstemmer\n",
      "Successfully installed snowballstemmer-2.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (d:\\downloads\\anaconda_god\\envs\\aravind\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\downloads\\anaconda_god\\envs\\aravind\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\downloads\\anaconda_god\\envs\\aravind\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\downloads\\anaconda_god\\envs\\aravind\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\downloads\\anaconda_god\\envs\\aravind\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\downloads\\anaconda_god\\envs\\aravind\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\downloads\\anaconda_god\\envs\\aravind\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# !pip install snowballstemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2ed10b1-58ad-4dc9-9a53-4c7c5264f52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'prefer', 'not', 'to', 'argu']\n"
     ]
    }
   ],
   "source": [
    "# Let's see the Snowball stemmer in cod! \n",
    "import snowballstemmer\n",
    "stemmer = snowballstemmer.stemmer('english');  # initialize the stemmer \n",
    "\n",
    "print(stemmer.stemWords(\"I prefer not to argue\".split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1523e588-dcc3-4d05-9ede-1930ed7027eb",
   "metadata": {},
   "source": [
    "#### **`RegexpStemmer`** \n",
    "\n",
    "You can also construct your own `stemmer` using the `RegexpStemmer`. It takes a single regular\n",
    "expression (either compiled or as a string) and removes any prefix or suffix that matches the expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc4d4acf-f83d-41d3-a558-66baa1e48ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cook'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "stemmer = RegexpStemmer('ing')\n",
    "stemmer.stem('cooking')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2e178d-2726-49a1-93f4-855817a9ce53",
   "metadata": {},
   "source": [
    "#### **`LancasterStemmer class`**\n",
    "The functions of the LancasterStemmer class are just like the functions of the PorterStemmer\n",
    "class, but can produce slightly different results. It is known to be slightly more aggressive than the\n",
    "PorterStemmer functions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "58f19dca-0fad-4608-bda9-ce52f6e1248d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "stemmer.stem('eating')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992f135e-1687-4977-b4c0-6923025b35f6",
   "metadata": {},
   "source": [
    "**Note:** But most users can live with Porter and Snowball stemmer for a large number of use cases. In modern\n",
    "NLP applications, sometimes people even ignore stemming as a pre-processing step, so it typically\n",
    "depends on your domain and application. I would also like to tell you the fact that if you want to use\n",
    "some NLP taggers, like Part of Speech tagger (POS), NER or dependency parser, you should avoid\n",
    "stemming, because stemming will modify the token and this can result in a different result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cd52e2-45ca-4b0e-a8ee-ca77c6b6a4ec",
   "metadata": {},
   "source": [
    "### What is lemmatization? \n",
    "\n",
    "* Lemmatization is a more methodical way of converting all the grammatical/inflected forms of the root\n",
    "of the word. \n",
    "\n",
    "* Lemmatization uses `context` and `part of speech `to determine the inflected form of the word\n",
    "and applies different `normalization` rules for each part of speech to get the `root word (lemma)`. \n",
    "\n",
    "* For instance, a lemmatization process reduces the inflections, `\"am\"`, `\"are\",` and `\"is\"`, to the base form, `\"be\"`. \n",
    "\n",
    "* Lemmatization is helpful for normalizing text for text classification tasks or search engines, and a variety of other NLP tasks such as sentiment classification. It is particularly important when dealing with complex languages like Arabic and Spanish.\n",
    "\n",
    "<center><img src=\"https://drive.google.com/uc?export=view&id=1_-wxBOU_JebjdG1sxoobKYRCtX3dVF0L\" width=\"800\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "694d7eee-5564-4b96-8b15-1cfdfbb707bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I => -PRON-\n",
      "love => love\n",
      "coding => code\n",
      "and => and\n",
      "writing => write\n"
     ]
    }
   ],
   "source": [
    "## import the libraries\n",
    "import spacy\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm') \n",
    "## lemmatization\n",
    "doc = nlp(u'I love coding and writing')\n",
    "for word in doc:\n",
    "    print(word.text, \"=>\", word.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2d7739-4937-485c-b7bc-afafe4422995",
   "metadata": {},
   "source": [
    "Let's see some difference between `Lemmatization` and `stemming`~\n",
    "\n",
    "\n",
    "<center><img src=\"https://stringfixer.com/files/107654628.jpg\" width=\"800\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8766f80-3d9a-462a-89ff-8b44282b4f09",
   "metadata": {},
   "source": [
    "`Stemming`: Reduce inflectional forms. It's a heuristic process it remove the prefix and suffix to achieve the goal correctly.\n",
    "\n",
    "(vs)\n",
    "\n",
    "`Lemmatization`: Reduce inflectional forms. It's make the word to base form with the help of vocabulary and morphological analysis of words. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4961f7-6fca-4051-8efe-0786f341d6e0",
   "metadata": {},
   "source": [
    "\n",
    "<center><img src=\"https://www.altexsoft.com/media/2021/03/word-image.jpeg\" width=\"800\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13527804-41f5-4456-9753-27b280e9d923",
   "metadata": {},
   "source": [
    "### Reference: \n",
    "* [**Stemming in Natural Language Processing**](https://www.c-sharpcorner.com/blogs/stemming-in-natural-language-processing) \n",
    "* [**Nlp Basics(colab)**](https://colab.research.google.com/drive/18ZnEnXKLQkkJoBXMZR2rspkWSm9EiDuZ#scrollTo=0lVd74BE5BXK) \n",
    "* [**NLTK official Documentation**](https://www.nltk.org/_modules/nltk/stem/snowball.html) \n",
    "* [**SnowBall Stemmer**](https://pypi.org/project/snowballstemmer/)\n",
    "* [**Natural Language Processing with python and NLTK (Book)**](https://www.pdfdrive.com/natural-language-processing-python-and-nltk-d158232635.html)\n",
    "* [**spaCy documentation**](https://spacy.io/api/data-formats#lemmatization)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
