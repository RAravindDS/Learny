{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f4f2a8d-563a-48f0-9549-0b25952c1338",
   "metadata": {},
   "source": [
    "<center><h1> ùí≤‚ùÄùìáùíπùí©ùëíùìâ </h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b9cc37-f5c1-4391-a889-85a4c4713f7a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<center><img src=\"https://64.media.tumblr.com/3e099d2e7bafd29ca333fa826ad4aedf/8f834b66cd4f9269-a3/s500x750/7d65a3e7c2ab6e6471464db905bbe49f691f96e8.png\" width=\"500\"/></center> \n",
    "\n",
    "### **What is ùí≤‚ùÄùìáùíπùí©ùëíùìâ?**\n",
    "\n",
    "Understanding and analysing the meaning of words,and pre-processing textual data, can be a challenging task. To support this, we often use **lexicons**. A lexicon, word-hoard, wordbook, or word-stock is the vocabulary of a person, language, or branch of knowledge. We often map the text in our data to the lexicon, which, in turn, helps us understand the relationships between those words.\n",
    "\n",
    "A really useful lexical resource is [**WordNet**](https://wordnet.princeton.edu/) . Its unique semantic network helps us find word relations, synonyms, grammars, etc. This helps support NLP tasks such as sentiment analysis, automatic language translation, text similarity, and more.\n",
    "\n",
    "* Wordnet is a **lexical**( the sense (or meaning)) **database**. It contains many database for different langauges. \n",
    "* In other words, it's a dictionary designed specifically for natural language processing. \n",
    "* It helps to do lot of functions like synonyms, hypernyms, and more. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9d0731-6f6d-489e-b65e-c750b81b95ef",
   "metadata": {},
   "source": [
    "NLTK comes with a simple interface to look up words in WordNet.\n",
    "Let's start with **Synset**, It means grouping of **synonymns words**. Many words have only one synset, but some have several synset! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c86a3f87-089b-4e8e-b4a2-00c7ca8f0c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see in code! \n",
    "from nltk.corpus import wordnet   # import the wordnet! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9200f30e-739a-4bc6-be4f-f209fba9ffcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name of the word: natural_language_processing.n.01, \n",
      "Definition of the word: the branch of information science that deals with natural language information\n"
     ]
    }
   ],
   "source": [
    "syn = wordnet.synsets('nlp')  # you can give whatever name you want! Ex: wordnet.synsets('love') \n",
    "\n",
    "# Let's see name and definition of the particular word! \n",
    "for i in syn: \n",
    "    print(f'\\nName of the word: {i.name()}, \\nDefinition of the word: {i.definition()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505bdbe6-5e7e-403f-81c4-e10fe6b5c7ff",
   "metadata": {},
   "source": [
    "You can look up any word in WordNet using **`wordnet.synsets(word)`** to get a list of Synsets. The\n",
    "list may be empty if the word is not found. The list may also have quite a few elements, as some words\n",
    "can have many possible meanings, and, therefore, many Synsets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b33c3c2-adfa-4ee8-b9b8-f203c9d8555d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name of the word: love.n.01, \n",
      "Definition of the word: a strong positive emotion of regard and affection, \n",
      "Examples: ['his love for his work', 'children need a lot of love']\n"
     ]
    }
   ],
   "source": [
    "# some synset also have example function()\n",
    "\n",
    "syn = wordnet.synsets('love')\n",
    "for i in syn: \n",
    "    print(f'\\nName of the word: {i.name()}, \\nDefinition of the word: {i.definition()}, \\nExamples: {i.examples()}')\n",
    "    \n",
    "    break  # If you want to see more version of answer, comment this line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7d854d-38fe-4d98-a165-fa3d6d93776e",
   "metadata": {},
   "source": [
    "### Hypernyms & Hyponym\n",
    "\n",
    "General Term = **`Hypernym`**  Ex: I have a health issues. \n",
    "\n",
    "Specific Term = **`Hyponym`**  Ex: I have **Arrhythmia**(heart disease)\n",
    "\n",
    "<center><img src=\"https://static.wixstatic.com/media/623df4_de30635eef4d41058d005ce04e088eff~mv2.png/v1/fill/w_797,h_506,al_c/623df4_de30635eef4d41058d005ce04e088eff~mv2.png\" width=\"400\"/></center>\n",
    "\n",
    "Let's see about **Hypernyms**, Hypernyms provide a way to categorize and group words based on their similarity to each other. It also helps to calculate the similarity based on the distance between two words in the hypernym tree. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ca005b8a-3b7c-4adc-a748-491868331a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypernyms: [Synset('group.n.01')],  root hypernyms [Synset('entity.n.01')]\n",
      "Hypernyms: [Synset('group.n.01')],  root hypernyms [Synset('entity.n.01')]\n",
      "Hypernyms: [Synset('family.n.04')],  root hypernyms [Synset('entity.n.01')]\n",
      "Hypernyms: [Synset('group.n.01')],  root hypernyms [Synset('entity.n.01')]\n",
      "Hypernyms: [Synset('populate.v.02')],  root hypernyms [Synset('change.v.01')]\n",
      "Hypernyms: [Synset('populate.v.01')],  root hypernyms [Synset('be.v.03')]\n"
     ]
    }
   ],
   "source": [
    "# Let's look at the code! \n",
    "\n",
    "syn = wordnet.synsets('people') \n",
    "\n",
    "for a in syn:\n",
    "    print(f'Hypernyms: {a.hypernyms()},  root hypernyms {a.root_hypernyms()}')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6975ea84-f4f3-464b-a4b5-42bb581b0eee",
   "metadata": {},
   "source": [
    "Actually this are all tree structure, we can trace the tree structure using `hypernym_paths`. \n",
    "\n",
    "The `hypernym_paths()` method returns a list of lists, where each list starts at the root hypernym and\n",
    "ends with the original Synset. Most of the time, you'll only get one nested list of Synsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "71ef93a0-589d-4a16-921e-1c1a1da987de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Synset('entity.n.01'), Synset('abstraction.n.06'), Synset('group.n.01'), Synset('people.n.01')]]\n",
      "[[Synset('entity.n.01'), Synset('abstraction.n.06'), Synset('group.n.01'), Synset('citizenry.n.01')]]\n",
      "[[Synset('entity.n.01'), Synset('abstraction.n.06'), Synset('group.n.01'), Synset('social_group.n.01'), Synset('kin.n.02'), Synset('genealogy.n.01'), Synset('lineage.n.01'), Synset('family.n.04'), Synset('people.n.03')]]\n",
      "[[Synset('entity.n.01'), Synset('abstraction.n.06'), Synset('group.n.01'), Synset('multitude.n.03')]]\n",
      "[[Synset('change.v.01'), Synset('fill.v.01'), Synset('populate.v.02'), Synset('people.v.01')]]\n",
      "[[Synset('be.v.03'), Synset('populate.v.01'), Synset('people.v.02')]]\n"
     ]
    }
   ],
   "source": [
    "for a in syn: \n",
    "    print(a.hypernym_paths())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e031adf-182c-49d5-a2f6-6fed390f966e",
   "metadata": {},
   "source": [
    "### POS\n",
    "\n",
    "Now, Let's look at **`POS`**. \n",
    "\n",
    "Usually there are four common part-of-speech tags (or POS tags) found in WordNet. \n",
    "\n",
    "<center><img src=\"https://media.geeksforgeeks.org/wp-content/uploads/pos-2.jpg\" width=\"300\"/></center>\n",
    "\n",
    "These POS tags can be used to look up specific `Synsets` for a word. For example, the word `'great'`\n",
    "can be used as a noun or an adjective. In WordNet, `'great'` has 1 noun Synset and 6 adjective\n",
    "Synsets, as shown in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9fd0ed43-787d-4be3-b537-a418289fbe85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of synsets: 7\n",
      "Length of Noun 1\n",
      "Length of Adverb 6\n",
      "Length of Verb 41\n",
      "Lenght of Adjective 6\n"
     ]
    }
   ],
   "source": [
    "# Let's look at code! \n",
    "\n",
    "print('Length of synsets:',len(wordnet.synsets('great'))); \n",
    "print('Length of Noun', len(wordnet.synsets('great', pos = 'n')))\n",
    "print('Length of Adverb', len(wordnet.synsets('great', pos = 'av')))\n",
    "print(\"Length of Verb\", len(wordnet.synsets('run', pos = 'v')))\n",
    "print('Lenght of Adjective', len(wordnet.synsets('great', pos = 'a')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9b19c7-db15-4b1f-b990-7a577c0612a9",
   "metadata": {},
   "source": [
    "Let's use the **`Lemma`** here to understand the words, clearly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e1b3e4dd-25d3-495b-9859-1fa64d6542ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('love.v.01.love')]\n",
      "[Lemma('love.v.02.love'), Lemma('love.v.02.enjoy')]\n",
      "[Lemma('love.v.03.love')]\n",
      "[Lemma('sleep_together.v.01.sleep_together'), Lemma('sleep_together.v.01.roll_in_the_hay'), Lemma('sleep_together.v.01.love'), Lemma('sleep_together.v.01.make_out'), Lemma('sleep_together.v.01.make_love'), Lemma('sleep_together.v.01.sleep_with'), Lemma('sleep_together.v.01.get_laid'), Lemma('sleep_together.v.01.have_sex'), Lemma('sleep_together.v.01.know'), Lemma('sleep_together.v.01.do_it'), Lemma('sleep_together.v.01.be_intimate'), Lemma('sleep_together.v.01.have_intercourse'), Lemma('sleep_together.v.01.have_it_away'), Lemma('sleep_together.v.01.have_it_off'), Lemma('sleep_together.v.01.screw'), Lemma('sleep_together.v.01.fuck'), Lemma('sleep_together.v.01.jazz'), Lemma('sleep_together.v.01.eff'), Lemma('sleep_together.v.01.hump'), Lemma('sleep_together.v.01.lie_with'), Lemma('sleep_together.v.01.bed'), Lemma('sleep_together.v.01.have_a_go_at_it'), Lemma('sleep_together.v.01.bang'), Lemma('sleep_together.v.01.get_it_on'), Lemma('sleep_together.v.01.bonk')]\n",
      "[Lemma('loving.a.01.loving')]\n"
     ]
    }
   ],
   "source": [
    "syn = wordnet.synsets('loving')\n",
    "\n",
    "for i in syn: \n",
    "    print(i.lemmas())  # lemma word, too much word right! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "910ef175-a9c4-4552-be14-8b501a866814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of the lemma: love\n",
      "Name of the lemma: love\n",
      "Name of the lemma: love\n",
      "Name of the lemma: sleep_together\n",
      "Name of the lemma: loving\n"
     ]
    }
   ],
   "source": [
    "# Previous code not giving any sense, let's iterate the lemma and get some meaningful insights! \n",
    "for i in syn: \n",
    "    for j in i.lemmas():\n",
    "        print(f'Name of the lemma: {j.name()}')\n",
    "        \n",
    "        break  # want to see more words, just comment this line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7889d9e3-9e97-40f9-a2ff-b4bb98182dec",
   "metadata": {},
   "source": [
    "In fact, a\n",
    "lemma can only belong to a single Synset. In this way, a Synset represents a group of lemmas that all\n",
    "have the same meaning, while a lemma represents a distinct word form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0b0984af-14ec-4e0f-abd4-0f788e667cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['love']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[lemma.name() for lemma in syn[0].lemmas()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a90db4-fed7-4d00-8390-0537fc09661e",
   "metadata": {},
   "source": [
    "### Synonymns \n",
    "\n",
    "As mentioned earlier, many words have multiple Synsets because the word can have different meanings\n",
    "depending on the context. But, let's say you didn't care about the context, and wanted to get all the\n",
    "possible synonyms for a word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0c61c31e-b76c-4b8d-b6c6-75f6c02bcad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['book', 'book', 'volume', 'record', 'record_book', 'book', 'script', 'book', 'playscript', 'ledger', 'leger', 'account_book', 'book_of_account', 'book', 'book', 'book', 'rule_book', 'Koran', 'Quran', \"al-Qur'an\", 'Book', 'Bible', 'Christian_Bible', 'Book', 'Good_Book', 'Holy_Scripture', 'Holy_Writ', 'Scripture', 'Word_of_God', 'Word', 'book', 'book', 'book', 'reserve', 'hold', 'book', 'book', 'book']\n"
     ]
    }
   ],
   "source": [
    "# @Code to get all synonyms\n",
    "\n",
    "synonyms = []\n",
    "for syn in wordnet.synsets('book'):\n",
    "    for lemma in syn.lemmas():\n",
    "        synonyms.append(lemma.name())\n",
    "\n",
    "print(synonyms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26de157e-ff3f-4ed9-adc8-417c422c6eda",
   "metadata": {},
   "source": [
    "As you can see, there appears to be 38 possible synonyms for the word 'book'. But in fact, some\n",
    "synonyms are verb forms, and many synonyms are just different usages of 'book'. If, instead, we take\n",
    "the set of synonyms, there are fewer unique words, as shown in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bf9c92f6-c2ed-495c-83ff-61e46a63a244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(synonyms))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c7d66c-114f-4cee-a819-7260c6dd21ed",
   "metadata": {},
   "source": [
    "### Antonyms\n",
    "\n",
    "The antonyms() method returns a list of lemmas. \n",
    "\n",
    "Some lemmas also have antonyms. The word `good`, for example, has 27 Synsets, five of which have lemmas with antonyms, as shown in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6a9a7c4b-c6e3-4d9f-a172-e41c210cdbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the good synonyms: 27 \n",
      "\n",
      "\u001b[31mName: \u001b[32mgood.n.01\n",
      "\u001b[31mDefinition: \u001b[32mbenefit\n",
      "\u001b[31mAntonyms: \u001b[32m[]\n",
      "\u001b[34m==========================================================================\n"
     ]
    }
   ],
   "source": [
    "from colorama import Fore\n",
    "gn2 = wordnet.synsets('good')\n",
    "print(F'Length of the good synonyms: {len(gn2)} \\n') \n",
    "\n",
    "for i in gn2: \n",
    "    print(f\"{Fore.RED + 'Name'}: {Fore.GREEN + str(i.name())}\")\n",
    "    print(f\"{Fore.RED + 'Definition'}: {Fore.GREEN + str(i.definition())}\")\n",
    "    print(f\"{Fore.RED + 'Antonyms'}: {Fore.GREEN + str(i.lemmas()[0].antonyms())}\")\n",
    "    print(Fore.BLUE + '==========================================================================')\n",
    "    \n",
    "    \n",
    "    break   # want to see more output, comment this line! \n",
    "    \n",
    "    \n",
    "    \n",
    "# Just try one line code! \n",
    "# wordnet.synsets('love')[0].lemmas()[0].antonyms()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52ac35f-ac2d-4946-af6c-650d83ed7285",
   "metadata": {},
   "source": [
    "### Synset Similarity\n",
    "\n",
    "**Synsets are organized in a hypernym tree. This tree can be used for reasoning about the similarity\n",
    "between the Synsets it contains. The closer the two Synsets are in the tree, the more similar they are.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9de95919-3037-43aa-9ffc-8e1e628c74fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9166666666666666"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we are going to find synset simiarity between two words!\n",
    " \n",
    "syn1 = wordnet.synsets('cookbook')[0]  # first word \n",
    "syn2 = wordnet.synsets('instruction_book')[0]  # second word \n",
    "\n",
    "syn1.wup_similarity(syn2)  # wup_similarity helps to find the synset similarity!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5d566a3f-b6e6-4775-8efb-391c8a48b530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try with other words! \n",
    "syn1 = wordnet.synsets('love')[0]  # first word \n",
    "syn2 = wordnet.synsets('caring')[0]  # second word \n",
    "\n",
    "syn1.wup_similarity(syn2)  # wup_similarity helps to find the synset similarity!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d17198-c677-4aeb-bf4d-c8e39a5ff212",
   "metadata": {},
   "source": [
    "#### Wu-Palmer Similarity Score \n",
    "\n",
    "The wup_similarity method is short for Wu-Palmer Similarity, which is a scoring method based\n",
    "on how similar the word senses are and where the Synsets occur relative to each other in the hypernym\n",
    "tree. \n",
    "\n",
    "<center><img src=\"https://miro.medium.com/max/1380/0*6OUPcKbpE6PBOtdk.jpg\" width=\"600\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "47980346-3d89-49b5-9d11-b1b6e3532dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try to compare verbs \n",
    "\n",
    "syn1 = wordnet.synsets('run', pos = 'v')[0]\n",
    "syn2 = wordnet.synsets('moving', pos = 'v')[0]\n",
    "\n",
    "syn1.wup_similarity(syn2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b4ef28-64d0-43b7-963c-367c5477b9c7",
   "metadata": {},
   "source": [
    "### Tagging\n",
    "\n",
    "Let's try to do tagging with the help of **`WordNet`**.  WordNet Synsets specify a part-of-speech tag. It's a very restricted set of\n",
    "possible tags, and many words have multiple Synsets with different part-of-speech tags, but this\n",
    "information can be useful for tagging unknown words. WordNet is essentially a giant dictionary, and it's\n",
    "likely to contain many words that are not in your training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf2329f-dd77-49f5-ad07-642d9c459f4e",
   "metadata": {},
   "source": [
    "#### Overall View \n",
    "\n",
    "Overall view of  what we have learnt!\n",
    "\n",
    "<center><img src=\"https://cornetto.clarin.inl.nl/help/img/visualization-big-example.png\" width=\"800\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae7df1e-bae5-4028-842a-bccd5b0f02da",
   "metadata": {},
   "source": [
    "### **Reference**\n",
    "\n",
    "* [**Natural Language Processing with python and NLTK (Book)**](https://www.pdfdrive.com/natural-language-processing-python-and-nltk-d158232635.html) \n",
    "\n",
    "* [**Introduction to WordNet (Blog)**](https://towardsdatascience.com/%EF%B8%8Fwordnet-a-lexical-taxonomy-of-english-words-4373b541cfff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
