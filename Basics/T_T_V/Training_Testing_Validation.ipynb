{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6715a414-5e61-464a-b5fe-f0113e0ff612",
   "metadata": {},
   "source": [
    "<center><h1>𝓣𝓻𝓪𝓲𝓷𝓲𝓷𝓰 𝓭𝓪𝓽𝓪 𝓪𝓷𝓭 𝓽𝓮𝓼𝓽𝓲𝓷𝓰 𝓭𝓪𝓽𝓪!</h1></center>\n",
    "\n",
    "<center><img src=\"https://miro.medium.com/max/1400/1*Nv2NNALuokZEcV6hYEHdGA.png\" width=\"600\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef13464b-5be3-415b-92ce-ff9ce549b2ae",
   "metadata": {},
   "source": [
    "\n",
    "> 𝑀𝒶𝒸𝒽𝒾𝓃𝑒 𝓁𝑒𝒶𝓇𝓃𝒾𝓃𝑔 𝒾𝓈 𝓃𝑜𝓉 𝑜𝓃𝓁𝓎 𝒶𝒷𝑜𝓊𝓉 𝑒𝓈𝓉𝒾𝓂𝒶𝓉𝒾𝓃𝑔 𝓉𝒽𝑒 𝓇𝑒𝓈𝓊𝓁𝓉𝓈, 𝒾𝓉'𝓈 𝒶𝓁𝓈𝑜 𝒶𝒷𝑜𝓊𝓉 𝒽𝑜𝓌 𝓌𝑒𝓁𝓁 𝓎𝑜𝓊 𝒶𝓇𝑒 𝑒𝓈𝓉𝒾𝓂𝒶𝓉𝒾𝓃𝑔 𝓉𝒽𝑒 𝓇𝑒𝓈𝓊𝓁𝓉𝓈!\n",
    "\n",
    "For estimating the results correctly, we should test the model with different types of data not seen in the training set. Let's go deeper to this concept! \n",
    "\n",
    "### Overall view \n",
    "- Consider you are going to teach a newborn baby (In our case \"model\"). You can teach whatever you want but if you want to find whether the baby understands your teaching or not you should give a test to the baby right? \n",
    "- For testing the baby, you can ask new questions about what you taught. If the baby answered correctly, it's fine otherwise you need to teach more.\n",
    "- This is what exactly `training and testing` data is. You are going to train the model with some amount of data, and if you want to find your model to understand the pattern you can ask the new question it has not seen before, if it's giving good results your model is good otherwise you need to train more. \n",
    "\n",
    "\n",
    "#### 1. Training Data \n",
    "- The training data is the biggest (in term of size) set created out of the original dataset. \n",
    "- It is used to teach the model.\n",
    "- Model learns the parameters by using this dataset. \n",
    "- Training data needs to be bigger in size because the model learns the pattern by using trianing data. \n",
    "- Training data should be `randomized` for better training. \n",
    "- It is used to predict the new data it has not seen before, so training data should be big in size. \n",
    "\n",
    "<center><img src=\"https://miro.medium.com/max/1400/1*RJS8yV5mBDqrRu7THooH-w.png\" width=\"600\"/></center>\n",
    "\n",
    "#### 2. Validation Data \n",
    "- Training data helps to teach the model (understand the patterns and learns the features), we need to cross check the model. \n",
    "- So, we use validation data. It's just a another split of orignial data, this data does not contain any data present in the training data. It's an unique data. \n",
    "- When working with Machine Learning models, you typically need to test multiple models with different hyper-parameter values in order to find the optimal values that will give the best possible performance. Therefore, in order to pick objectively the “best” model you need to evaluate each of them.\n",
    "- For instance, in Deep Learning we use the validation set in order to find the optimal network layer size, the number of hidden units and the regularization term.\n",
    "- For evaluvating model to find the best hyper parameter you can use validation data. \n",
    "- Validation data is used in `hyper-parameter tunning` and `model selection`. \n",
    "- It is also called by `holdout sample`\n",
    "\n",
    "<center><img src=\"https://www.brainstobytes.com/content/images/2020/01/Sets.png\" width=\"600\"/></center>\n",
    "\n",
    "#### 3. Testing data \n",
    "- Now that you have tuned the model by performing hyper-parameter optimisation, you should end up with the final model. The testing set is used to evaluate the performance of this model and ensure that it can generalise well to new, unseen data points.\n",
    "- This set contains unique data not present in the validation and training data. \n",
    "- As like we previously discussed to test a model, we use different set. \n",
    "- Testing data is very unique during training the model because model don't see this data while training. \n",
    "- Testing data should be sequential.  \n",
    "\n",
    "<center><img src=\"https://francisbrochu.github.io/microbiome-summer-school-2017_mass-spec/sections/machine_learning/figures/train_test_sets.png\" width=\"600\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3497800-ff74-4ba5-87f1-55307a09f307",
   "metadata": {},
   "source": [
    "**let's see in code!**\n",
    "\n",
    ">  Sklearn train test split is not enough. We need something better, and faster!\n",
    "\n",
    "We split this data in random way! \n",
    "<center><img src=\"https://miro.medium.com/max/875/1*f2KznlrIdj1MeobprVGBtg.png\" width=\"600\"/></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2657a07-45fd-4e5d-be13-472f00148247",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (d:\\downloads\\anaconda_god\\envs\\aravind\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\downloads\\anaconda_god\\envs\\aravind\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\downloads\\anaconda_god\\envs\\aravind\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\downloads\\anaconda_god\\envs\\aravind\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\downloads\\anaconda_god\\envs\\aravind\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\downloads\\anaconda_god\\envs\\aravind\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\downloads\\anaconda_god\\envs\\aravind\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fast-ml\n",
      "  Downloading fast_ml-3.68-py3-none-any.whl (42 kB)\n",
      "Installing collected packages: fast-ml\n",
      "Successfully installed fast-ml-3.68\n"
     ]
    }
   ],
   "source": [
    "!pip install fast-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d3af4e0-5833-401a-addb-0b28ed5d8a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import \n",
    "import pandas as pd  # for reading the csv \n",
    "from fast_ml.model_development import train_valid_test_split  # for splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6994cc1-0bd8-43b5-97d1-bc6323c35912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>ProdTaken</th>\n",
       "      <th>Age</th>\n",
       "      <th>TypeofContact</th>\n",
       "      <th>CityTier</th>\n",
       "      <th>DurationOfPitch</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Gender</th>\n",
       "      <th>NumberOfPersonVisiting</th>\n",
       "      <th>NumberOfFollowups</th>\n",
       "      <th>ProductPitched</th>\n",
       "      <th>PreferredPropertyStar</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>NumberOfTrips</th>\n",
       "      <th>Passport</th>\n",
       "      <th>PitchSatisfactionScore</th>\n",
       "      <th>OwnCar</th>\n",
       "      <th>NumberOfChildrenVisiting</th>\n",
       "      <th>Designation</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20993.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200001</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200002</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Free Lancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17090.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200003</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200004</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Small Business</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>18468.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  ProdTaken   Age    TypeofContact  CityTier  DurationOfPitch  \\\n",
       "0      200000          1  41.0     Self Enquiry         3              6.0   \n",
       "1      200001          0  49.0  Company Invited         1             14.0   \n",
       "2      200002          1  37.0     Self Enquiry         1              8.0   \n",
       "3      200003          0  33.0  Company Invited         1              9.0   \n",
       "4      200004          0   NaN     Self Enquiry         1              8.0   \n",
       "\n",
       "       Occupation  Gender  NumberOfPersonVisiting  NumberOfFollowups  \\\n",
       "0        Salaried  Female                       3                3.0   \n",
       "1        Salaried    Male                       3                4.0   \n",
       "2     Free Lancer    Male                       3                4.0   \n",
       "3        Salaried  Female                       2                3.0   \n",
       "4  Small Business    Male                       2                3.0   \n",
       "\n",
       "  ProductPitched  PreferredPropertyStar MaritalStatus  NumberOfTrips  \\\n",
       "0         Deluxe                    3.0        Single            1.0   \n",
       "1         Deluxe                    4.0      Divorced            2.0   \n",
       "2          Basic                    3.0        Single            7.0   \n",
       "3          Basic                    3.0      Divorced            2.0   \n",
       "4          Basic                    4.0      Divorced            1.0   \n",
       "\n",
       "   Passport  PitchSatisfactionScore  OwnCar  NumberOfChildrenVisiting  \\\n",
       "0         1                       2       1                       0.0   \n",
       "1         0                       3       1                       2.0   \n",
       "2         1                       3       0                       0.0   \n",
       "3         1                       5       1                       1.0   \n",
       "4         0                       5       1                       0.0   \n",
       "\n",
       "  Designation  MonthlyIncome  \n",
       "0     Manager        20993.0  \n",
       "1     Manager        20130.0  \n",
       "2   Executive        17090.0  \n",
       "3   Executive        17909.0  \n",
       "4   Executive        18468.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data \n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/RAravindDS/Dataset/main/Travel.csv\") \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad37d2b1-a192-439c-a517-88056a29a820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data! \n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test = train_valid_test_split(data,                      # data \n",
    "                                                                            target = 'MonthlyIncome',  # target column name\n",
    "                                                                            train_size=0.8,            # training data split size    \n",
    "                                                                            valid_size=0.1,            # validation data split size  \n",
    "                                                                            test_size=0.1)             # testing data split size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f39d3f9-0c81-48a1-9fc6-8ca6cf43ceb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of xtrain and ytrain ((3910, 19), (3910,))\n",
      "\n",
      "Size of xtest and ytest ((489, 19), (489,))\n",
      "\n",
      "Size of xvalid and yvalid ((489, 19), (489,))\n"
     ]
    }
   ],
   "source": [
    "# let's check the size of each split: \n",
    "print(f'Size of xtrain and ytrain {X_train.shape, y_train.shape}')\n",
    "print(f'\\nSize of xtest and ytest {X_test.shape, y_test.shape}') \n",
    "print(f'\\nSize of xvalid and yvalid {X_valid.shape, y_valid.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbf436b8-00f4-4afc-b636-1b57c512d7fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4888, 20)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overall size of the data \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f40c511e-b02f-4da1-88c3-b70605834b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3910"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross check the split \n",
    "train_size_ = int(0.8 * len(data))  # 80% of the overall data! \n",
    "train_size_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4415e6-0617-4fad-823b-880e379f280e",
   "metadata": {},
   "source": [
    "Fine! Another way to find your model performance using `K Fold cross validation`. \n",
    "\n",
    "### K Fold Cross Validatiaon \n",
    "- We randomly split the data for train, test, and validation split in normal method (trian_test_valid split). But no one knows which split is good for testing, validation, and training. No one knows which set is suitalbe for giving good results. But changing the split can improve some amount of accuracy in our model. \n",
    "- But how do we find which split is good? For this we use the `cross validation`. \n",
    "-  When we’re not told which data should be used for Training and for Testing, we can use Cross Validation to figure out which is which in an unbiased way. \n",
    "- Rather than worry too much about which specific  points are best for Training and best for Testing,  Cross Validation uses all points for both in an iterative way, meaning that we use them in steps\n",
    "\n",
    "\n",
    "<center><img src=\"https://cs.calvin.edu/courses/data/202/ka37/slides/w11/w11d1-cv-review_files/figure-html/cv-anim-.gif\" width=\"600\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd943d17-ee74-40af-b67f-0eeb4dd3ba9a",
   "metadata": {},
   "source": [
    "- Cross Validation solves the problem of not knowing which points \n",
    "are the best for Testing by using them all in an iterative way. \n",
    "\n",
    "\n",
    "**Example:**\n",
    "<center><img src=\"https://miro.medium.com/max/1046/1*C5FJt_NH1BWJrFSvw_6jtw.png\" width=\"600\"/></center>\n",
    "\n",
    "- Split the entire data randomly into K folds (value of K shouldn’t be too small or too high, ideally we choose 5 to 10 depending on the data size). The higher value of K leads to less biased model (but large variance might lead to over-fit), where as the lower value of K is similar to the train-test split approach we saw before.\n",
    "- Then fit the model using the K-1 (K minus 1) folds and validate the model using the remaining Kth fold. Note down the scores/errors.\n",
    "- Repeat this process until every K-fold serve as the test set. Then take the average of your recorded scores. That will be the performance metric for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af4d79a-3736-45c9-b345-6720a2b85272",
   "metadata": {},
   "source": [
    "The general procedure is as follows:\n",
    "\n",
    "1. Shuffle the dataset randomly.\n",
    "2. Split the dataset into k groups\n",
    "3. For each unique group:\n",
    "    1. Take the group as a hold out or test data set\n",
    "    2. Take the remaining groups as a training data set\n",
    "    3. Fit a model on the training set and evaluate it on the test set\n",
    "    4. Retain the evaluation score and discard the model\n",
    "4. Summarize the skill of the model using the sample of model evaluation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83c65942-bddb-4145-b3f8-804208fdf2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33150734 0.08022311 0.03531764]\n"
     ]
    }
   ],
   "source": [
    "# let's see in code \n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "diabetes = datasets.load_diabetes()  # getting the datasets\n",
    "X = diabetes.data[:150]              \n",
    "y = diabetes.target[:150]\n",
    "\n",
    "lasso = linear_model.Lasso()         # lasso regression model \n",
    "print(cross_val_score(lasso, X, y, cv=3))    # cross validation here we are specifing the k fold as 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9195d252-25ae-4ce9-a364-1518751ee458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14901602799979094"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "me = cross_val_score(lasso, X, y, cv=3, scoring = 'r2')\n",
    "np.mean(me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0e450dfd-4ba6-4b0d-9475-e639029a827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to learn what are all the scoring available, uncomment and run it! \n",
    "import sklearn\n",
    "# sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e1c453-e7c1-486b-9704-71a88755399a",
   "metadata": {},
   "source": [
    "### Reference\n",
    "* [**ML Mastery**](https://machinelearningmastery.com/k-fold-cross-validation/) \n",
    "* [**StatQuest**](https://www.amazon.com/StatQuest-Illustrated-Guide-Machine-Learning/dp/B09ZCKR4H6/ref=sr_1_1?crid=31Y4X26TG7ZUF&keywords=statquest&qid=1655602350&s=books&sprefix=stat%2Cstripbooks-intl-ship%2C1170&sr=1-1)  Page Number - 22"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
